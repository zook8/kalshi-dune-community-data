name: Daily Kalshi Data Pipeline

on:
  schedule:
    # Run daily at 12:00 UTC (7 AM EST / 8 AM EDT)
    - cron: '0 12 * * *'
  workflow_dispatch:  # Allow manual triggers for testing

jobs:
  kalshi-pipeline:
    runs-on: ubuntu-latest
    timeout-minutes: 30  # Prevent runaway jobs

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Create necessary directories
        run: |
          mkdir -p logs data

      - name: Run Kalshi Data Pipeline
        env:
          DUNE_API_KEY: ${{ secrets.DUNE_API_KEY }}
          APPEND_MODE: "true"  # Enable append mode for historical data preservation
        run: |
          echo "Starting Kalshi data collection and upload pipeline..."
          python scripts/run_pipeline.py

      - name: Upload logs (on failure)
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-logs-${{ github.run_number }}
          path: logs/
          retention-days: 7

      - name: Cleanup temporary files
        if: always()
        run: |
          # Clean up any temporary CSV files to avoid accumulation
          rm -f data/*.csv
          echo "Cleanup completed"